# stt-utils

[![PyPI version](https://badge.fury.io/py/stt-utils.svg)](https://pypi.org/project/stt-utils/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A utility library for working with word-level speech-to-text timestamps. The main goal is to simplify working with timestamps generated by openai's whisper model with "word" timestamp_granularities.

## Features
- Realign word timestamps with the full text
- Merge several transcriptions together
- (Optional dependency) Split long audio into smaller segments by the moments of silence.

## Installation

```bash
pip install stt-utils
```

With audio tools support:

```bash
pip install "stt-utils[audio]"
```

## Usage

Align word timestamps from openai whisper
```python
from stt_utils import UnprocessedTranscription, Transcription

transcription = openai_client.audio.transcriptions.create(
    model="whisper-1",
    file=audio_file,
    response_format="verbose_json",
    timestamp_granularities=["word"],
)

unprocessed_transcription = UnprocessedTranscription(**transcription.model_dump())
aligned_transcription = Transcription.from_unprocessed_transcription(unprocessed_transcription)

aligned_transcription.dump_prevew()
```

Split an audio file in roughly 10 minute segments with splits in moments of silence.
```python
from stt_utils import split_audio_on_silence
from pydub import AudioSegment

audio = AudioSegment.from_file("example_audio.mp3")

splitted = split_audio_on_silence(audio)

for i, segment in enumerate(splitted):
    segment.export(f"segment_{i}.wav")
```

## Testing
There are unittests available in the `tests/` directory.
```
uv run pytest
```


## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.